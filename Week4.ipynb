{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "287625eb-0bf6-413b-8fd0-23464b759279",
   "metadata": {},
   "source": [
    "# Supervised Learning and Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22735644-01c0-4b9f-97fa-b7602ebc48e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('./heart_failure_clinical_records_dataset.csv') #make sure to replace with your data directory\n",
    "df.drop(columns=['time'],inplace=True) #drop the time column which is not one of the informative features \n",
    "df_features = df.iloc[:,:-1]\n",
    "df_target = df['DEATH_EVENT']\n",
    "\n",
    "X = df_features\n",
    "y = df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b10ca066-df7e-4f98-a891-e329fbc4b8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>155000.00</td>\n",
       "      <td>1.1</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1820</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2060</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>742000.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2413</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>140000.00</td>\n",
       "      <td>1.4</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>395000.00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0    75.0        0                       582         0                 20   \n",
       "1    55.0        0                      7861         0                 38   \n",
       "2    65.0        0                       146         0                 20   \n",
       "3    50.0        1                       111         0                 20   \n",
       "4    65.0        1                       160         1                 20   \n",
       "..    ...      ...                       ...       ...                ...   \n",
       "294  62.0        0                        61         1                 38   \n",
       "295  55.0        0                      1820         0                 38   \n",
       "296  45.0        0                      2060         1                 60   \n",
       "297  45.0        0                      2413         0                 38   \n",
       "298  50.0        0                       196         0                 45   \n",
       "\n",
       "     high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                      1  265000.00               1.9           130    1   \n",
       "1                      0  263358.03               1.1           136    1   \n",
       "2                      0  162000.00               1.3           129    1   \n",
       "3                      0  210000.00               1.9           137    1   \n",
       "4                      0  327000.00               2.7           116    0   \n",
       "..                   ...        ...               ...           ...  ...   \n",
       "294                    1  155000.00               1.1           143    1   \n",
       "295                    0  270000.00               1.2           139    0   \n",
       "296                    0  742000.00               0.8           138    0   \n",
       "297                    0  140000.00               1.4           140    1   \n",
       "298                    0  395000.00               1.6           136    1   \n",
       "\n",
       "     smoking  \n",
       "0          0  \n",
       "1          0  \n",
       "2          1  \n",
       "3          0  \n",
       "4          0  \n",
       "..       ...  \n",
       "294        1  \n",
       "295        0  \n",
       "296        0  \n",
       "297        1  \n",
       "298        1  \n",
       "\n",
       "[299 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b042fd7c-7f80-48b0-bb2f-f4d1373b687f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "294    0\n",
       "295    0\n",
       "296    0\n",
       "297    0\n",
       "298    0\n",
       "Name: DEATH_EVENT, Length: 299, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63280080-f770-4f9d-9535-d8ca904a1dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DEATH_EVENT\n",
       "0    203\n",
       "1     96\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a715f5-8bfe-4244-9d66-01647fadfca9",
   "metadata": {},
   "source": [
    "# Create train and test sets\n",
    "\n",
    "We should divide the dataset to train and test splits. We train our ML algorithms on train dataset and evaluate their performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "910c1e2e-5529-4968-99f6-59648995536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,stratify=y,random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "990856a4-c00e-468c-95bc-988e773bb0dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209, 11)\n",
      "(209,)\n",
      "(90, 11)\n",
      "(90,)\n",
      "y train:  DEATH_EVENT\n",
      "0    0.679426\n",
      "1    0.320574\n",
      "Name: proportion, dtype: float64\n",
      "y test:  DEATH_EVENT\n",
      "0    0.677778\n",
      "1    0.322222\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print('y train: ',y_train.value_counts(normalize=True))\n",
    "print('y test: ',y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c36c5e4-5fdd-4459-8f29-5d156d3d9193",
   "metadata": {},
   "source": [
    "A model with random guess which always predict the majority group has 68% accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091f5147-95ec-4e9c-8379-459c0741ec8a",
   "metadata": {},
   "source": [
    "# Normalize train and test sets separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb9e4644-9efd-43d1-a380-f6ccb729c8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "X_train = zscore(X_train)\n",
    "X_test = zscore(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66daf195-ddb0-48b9-9b0c-853a54a9621e",
   "metadata": {},
   "source": [
    "# Logistic regression Model \n",
    "\n",
    "1- Establish your model \n",
    "\n",
    "2- Fit your model \n",
    "\n",
    "3- Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da6cf637-0b5f-44b6-9c63-f5ca8df2a13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7111111111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e013714c-3b80-4399-8daf-3cb4d1b0bc75",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "## Exercise: Train a Random Forest model on train set and identify the accuracy on test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3df99cb1-a4fa-414f-ae2b-4c34efb6cbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "#Write your code here\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d049677d-d44a-43f3-bebe-64baca1f3ad3",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fcd629b-5f0b-4263-ade0-1841d43e8b2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mInit signature:\u001b[39m\n",
       "SVC(\n",
       "    *,\n",
       "    C=\u001b[32m1.0\u001b[39m,\n",
       "    kernel=\u001b[33m'rbf'\u001b[39m,\n",
       "    degree=\u001b[32m3\u001b[39m,\n",
       "    gamma=\u001b[33m'scale'\u001b[39m,\n",
       "    coef0=\u001b[32m0.0\u001b[39m,\n",
       "    shrinking=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
       "    probability=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    tol=\u001b[32m0.001\u001b[39m,\n",
       "    cache_size=\u001b[32m200\u001b[39m,\n",
       "    class_weight=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    verbose=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    max_iter=-\u001b[32m1\u001b[39m,\n",
       "    decision_function_shape=\u001b[33m'ovr'\u001b[39m,\n",
       "    break_ties=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    random_state=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
       ")\n",
       "\u001b[31mDocstring:\u001b[39m     \n",
       "C-Support Vector Classification.\n",
       "\n",
       "The implementation is based on libsvm. The fit time scales at least\n",
       "quadratically with the number of samples and may be impractical\n",
       "beyond tens of thousands of samples. For large datasets\n",
       "consider using :class:`~sklearn.svm.LinearSVC` or\n",
       ":class:`~sklearn.linear_model.SGDClassifier` instead, possibly after a\n",
       ":class:`~sklearn.kernel_approximation.Nystroem` transformer or\n",
       "other :ref:`kernel_approximation`.\n",
       "\n",
       "The multiclass support is handled according to a one-vs-one scheme.\n",
       "\n",
       "For details on the precise mathematical formulation of the provided\n",
       "kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
       "other, see the corresponding section in the narrative documentation:\n",
       ":ref:`svm_kernels`.\n",
       "\n",
       "To learn how to tune SVC's hyperparameters, see the following example:\n",
       ":ref:`sphx_glr_auto_examples_model_selection_plot_nested_cross_validation_iris.py`\n",
       "\n",
       "Read more in the :ref:`User Guide <svm_classification>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "C : float, default=1.0\n",
       "    Regularization parameter. The strength of the regularization is\n",
       "    inversely proportional to C. Must be strictly positive. The penalty\n",
       "    is a squared l2 penalty. For an intuitive visualization of the effects\n",
       "    of scaling the regularization parameter C, see\n",
       "    :ref:`sphx_glr_auto_examples_svm_plot_svm_scale_c.py`.\n",
       "\n",
       "kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'} or callable,          default='rbf'\n",
       "    Specifies the kernel type to be used in the algorithm. If\n",
       "    none is given, 'rbf' will be used. If a callable is given it is used to\n",
       "    pre-compute the kernel matrix from data matrices; that matrix should be\n",
       "    an array of shape ``(n_samples, n_samples)``. For an intuitive\n",
       "    visualization of different kernel types see\n",
       "    :ref:`sphx_glr_auto_examples_svm_plot_svm_kernels.py`.\n",
       "\n",
       "degree : int, default=3\n",
       "    Degree of the polynomial kernel function ('poly').\n",
       "    Must be non-negative. Ignored by all other kernels.\n",
       "\n",
       "gamma : {'scale', 'auto'} or float, default='scale'\n",
       "    Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
       "\n",
       "    - if ``gamma='scale'`` (default) is passed then it uses\n",
       "      1 / (n_features * X.var()) as value of gamma,\n",
       "    - if 'auto', uses 1 / n_features\n",
       "    - if float, must be non-negative.\n",
       "\n",
       "    .. versionchanged:: 0.22\n",
       "       The default value of ``gamma`` changed from 'auto' to 'scale'.\n",
       "\n",
       "coef0 : float, default=0.0\n",
       "    Independent term in kernel function.\n",
       "    It is only significant in 'poly' and 'sigmoid'.\n",
       "\n",
       "shrinking : bool, default=True\n",
       "    Whether to use the shrinking heuristic.\n",
       "    See the :ref:`User Guide <shrinking_svm>`.\n",
       "\n",
       "probability : bool, default=False\n",
       "    Whether to enable probability estimates. This must be enabled prior\n",
       "    to calling `fit`, will slow down that method as it internally uses\n",
       "    5-fold cross-validation, and `predict_proba` may be inconsistent with\n",
       "    `predict`. Read more in the :ref:`User Guide <scores_probabilities>`.\n",
       "\n",
       "tol : float, default=1e-3\n",
       "    Tolerance for stopping criterion.\n",
       "\n",
       "cache_size : float, default=200\n",
       "    Specify the size of the kernel cache (in MB).\n",
       "\n",
       "class_weight : dict or 'balanced', default=None\n",
       "    Set the parameter C of class i to class_weight[i]*C for\n",
       "    SVC. If not given, all classes are supposed to have\n",
       "    weight one.\n",
       "    The \"balanced\" mode uses the values of y to automatically adjust\n",
       "    weights inversely proportional to class frequencies in the input data\n",
       "    as ``n_samples / (n_classes * np.bincount(y))``.\n",
       "\n",
       "verbose : bool, default=False\n",
       "    Enable verbose output. Note that this setting takes advantage of a\n",
       "    per-process runtime setting in libsvm that, if enabled, may not work\n",
       "    properly in a multithreaded context.\n",
       "\n",
       "max_iter : int, default=-1\n",
       "    Hard limit on iterations within solver, or -1 for no limit.\n",
       "\n",
       "decision_function_shape : {'ovo', 'ovr'}, default='ovr'\n",
       "    Whether to return a one-vs-rest ('ovr') decision function of shape\n",
       "    (n_samples, n_classes) as all other classifiers, or the original\n",
       "    one-vs-one ('ovo') decision function of libsvm which has shape\n",
       "    (n_samples, n_classes * (n_classes - 1) / 2). However, note that\n",
       "    internally, one-vs-one ('ovo') is always used as a multi-class strategy\n",
       "    to train models; an ovr matrix is only constructed from the ovo matrix.\n",
       "    The parameter is ignored for binary classification.\n",
       "\n",
       "    .. versionchanged:: 0.19\n",
       "        decision_function_shape is 'ovr' by default.\n",
       "\n",
       "    .. versionadded:: 0.17\n",
       "       *decision_function_shape='ovr'* is recommended.\n",
       "\n",
       "    .. versionchanged:: 0.17\n",
       "       Deprecated *decision_function_shape='ovo' and None*.\n",
       "\n",
       "break_ties : bool, default=False\n",
       "    If true, ``decision_function_shape='ovr'``, and number of classes > 2,\n",
       "    :term:`predict` will break ties according to the confidence values of\n",
       "    :term:`decision_function`; otherwise the first class among the tied\n",
       "    classes is returned. Please note that breaking ties comes at a\n",
       "    relatively high computational cost compared to a simple predict. See\n",
       "    :ref:`sphx_glr_auto_examples_svm_plot_svm_tie_breaking.py` for an\n",
       "    example of its usage with ``decision_function_shape='ovr'``.\n",
       "\n",
       "    .. versionadded:: 0.22\n",
       "\n",
       "random_state : int, RandomState instance or None, default=None\n",
       "    Controls the pseudo random number generation for shuffling the data for\n",
       "    probability estimates. Ignored when `probability` is False.\n",
       "    Pass an int for reproducible output across multiple function calls.\n",
       "    See :term:`Glossary <random_state>`.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "class_weight_ : ndarray of shape (n_classes,)\n",
       "    Multipliers of parameter C for each class.\n",
       "    Computed based on the ``class_weight`` parameter.\n",
       "\n",
       "classes_ : ndarray of shape (n_classes,)\n",
       "    The classes labels.\n",
       "\n",
       "coef_ : ndarray of shape (n_classes * (n_classes - 1) / 2, n_features)\n",
       "    Weights assigned to the features (coefficients in the primal\n",
       "    problem). This is only available in the case of a linear kernel.\n",
       "\n",
       "    `coef_` is a readonly property derived from `dual_coef_` and\n",
       "    `support_vectors_`.\n",
       "\n",
       "dual_coef_ : ndarray of shape (n_classes -1, n_SV)\n",
       "    Dual coefficients of the support vector in the decision\n",
       "    function (see :ref:`sgd_mathematical_formulation`), multiplied by\n",
       "    their targets.\n",
       "    For multiclass, coefficient for all 1-vs-1 classifiers.\n",
       "    The layout of the coefficients in the multiclass case is somewhat\n",
       "    non-trivial. See the :ref:`multi-class section of the User Guide\n",
       "    <svm_multi_class>` for details.\n",
       "\n",
       "fit_status_ : int\n",
       "    0 if correctly fitted, 1 otherwise (will raise warning)\n",
       "\n",
       "intercept_ : ndarray of shape (n_classes * (n_classes - 1) / 2,)\n",
       "    Constants in decision function.\n",
       "\n",
       "n_features_in_ : int\n",
       "    Number of features seen during :term:`fit`.\n",
       "\n",
       "    .. versionadded:: 0.24\n",
       "\n",
       "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
       "    Names of features seen during :term:`fit`. Defined only when `X`\n",
       "    has feature names that are all strings.\n",
       "\n",
       "    .. versionadded:: 1.0\n",
       "\n",
       "n_iter_ : ndarray of shape (n_classes * (n_classes - 1) // 2,)\n",
       "    Number of iterations run by the optimization routine to fit the model.\n",
       "    The shape of this attribute depends on the number of models optimized\n",
       "    which in turn depends on the number of classes.\n",
       "\n",
       "    .. versionadded:: 1.1\n",
       "\n",
       "support_ : ndarray of shape (n_SV)\n",
       "    Indices of support vectors.\n",
       "\n",
       "support_vectors_ : ndarray of shape (n_SV, n_features)\n",
       "    Support vectors. An empty array if kernel is precomputed.\n",
       "\n",
       "n_support_ : ndarray of shape (n_classes,), dtype=int32\n",
       "    Number of support vectors for each class.\n",
       "\n",
       "probA_ : ndarray of shape (n_classes * (n_classes - 1) / 2)\n",
       "probB_ : ndarray of shape (n_classes * (n_classes - 1) / 2)\n",
       "    If `probability=True`, it corresponds to the parameters learned in\n",
       "    Platt scaling to produce probability estimates from decision values.\n",
       "    If `probability=False`, it's an empty array. Platt scaling uses the\n",
       "    logistic function\n",
       "    ``1 / (1 + exp(decision_value * probA_ + probB_))``\n",
       "    where ``probA_`` and ``probB_`` are learned from the dataset [2]_. For\n",
       "    more information on the multiclass case and training procedure see\n",
       "    section 8 of [1]_.\n",
       "\n",
       "shape_fit_ : tuple of int of shape (n_dimensions_of_X,)\n",
       "    Array dimensions of training vector ``X``.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "SVR : Support Vector Machine for Regression implemented using libsvm.\n",
       "\n",
       "LinearSVC : Scalable Linear Support Vector Machine for classification\n",
       "    implemented using liblinear. Check the See Also section of\n",
       "    LinearSVC for more comparison element.\n",
       "\n",
       "References\n",
       "----------\n",
       ".. [1] `LIBSVM: A Library for Support Vector Machines\n",
       "    <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`_\n",
       "\n",
       ".. [2] `Platt, John (1999). \"Probabilistic Outputs for Support Vector\n",
       "    Machines and Comparisons to Regularized Likelihood Methods\"\n",
       "    <https://citeseerx.ist.psu.edu/doc_view/pid/42e5ed832d4310ce4378c44d05570439df28a393>`_\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> import numpy as np\n",
       ">>> from sklearn.pipeline import make_pipeline\n",
       ">>> from sklearn.preprocessing import StandardScaler\n",
       ">>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
       ">>> y = np.array([1, 1, 2, 2])\n",
       ">>> from sklearn.svm import SVC\n",
       ">>> clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
       ">>> clf.fit(X, y)\n",
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svc', SVC(gamma='auto'))])\n",
       "\n",
       ">>> print(clf.predict([[-0.8, -1]]))\n",
       "[1]\n",
       "\n",
       "For a comparison of the SVC with other classifiers see:\n",
       ":ref:`sphx_glr_auto_examples_classification_plot_classification_probability.py`.\n",
       "\u001b[31mFile:\u001b[39m           /opt/anaconda3/envs/vmb_env_py311/lib/python3.11/site-packages/sklearn/svm/_classes.py\n",
       "\u001b[31mType:\u001b[39m           ABCMeta\n",
       "\u001b[31mSubclasses:\u001b[39m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SVC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a52a666-c0aa-49de-a4fc-1eccf58ac1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "#Linear SVM\n",
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train,y_train)\n",
    "preds = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1299dab4-d983-44e8-9e8c-17410d79c494",
   "metadata": {},
   "source": [
    "# Excercise: Run SVM for kernel based SVM (rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e75c294a-d53b-4809-a441-baef9d025a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729cea3f-ebc7-4758-8a7c-13eac5cc5e63",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f9fab3c5-8485-4b8d-97c1-9e41e84c0544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "preds = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a187ca3-6e75-4ae7-8a09-625f0235cc2a",
   "metadata": {},
   "source": [
    "# Dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bfdcec69-8aad-449f-831e-b923a7e2c59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6777777777777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_model = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_model.fit(X_train,y_train)\n",
    "preds = dummy_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3cb89653-5816-4615-a381-8f2466ef71b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mInit signature:\u001b[39m DummyClassifier(*, strategy=\u001b[33m'prior'\u001b[39m, random_state=\u001b[38;5;28;01mNone\u001b[39;00m, constant=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
       "\u001b[31mDocstring:\u001b[39m     \n",
       "DummyClassifier makes predictions that ignore the input features.\n",
       "\n",
       "This classifier serves as a simple baseline to compare against other more\n",
       "complex classifiers.\n",
       "\n",
       "The specific behavior of the baseline is selected with the `strategy`\n",
       "parameter.\n",
       "\n",
       "All strategies make predictions that ignore the input feature values passed\n",
       "as the `X` argument to `fit` and `predict`. The predictions, however,\n",
       "typically depend on values observed in the `y` parameter passed to `fit`.\n",
       "\n",
       "Note that the \"stratified\" and \"uniform\" strategies lead to\n",
       "non-deterministic predictions that can be rendered deterministic by setting\n",
       "the `random_state` parameter if needed. The other strategies are naturally\n",
       "deterministic and, once fit, always return the same constant prediction\n",
       "for any value of `X`.\n",
       "\n",
       "Read more in the :ref:`User Guide <dummy_estimators>`.\n",
       "\n",
       ".. versionadded:: 0.13\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "strategy : {\"most_frequent\", \"prior\", \"stratified\", \"uniform\",             \"constant\"}, default=\"prior\"\n",
       "    Strategy to use to generate predictions.\n",
       "\n",
       "    * \"most_frequent\": the `predict` method always returns the most\n",
       "      frequent class label in the observed `y` argument passed to `fit`.\n",
       "      The `predict_proba` method returns the matching one-hot encoded\n",
       "      vector.\n",
       "    * \"prior\": the `predict` method always returns the most frequent\n",
       "      class label in the observed `y` argument passed to `fit` (like\n",
       "      \"most_frequent\"). ``predict_proba`` always returns the empirical\n",
       "      class distribution of `y` also known as the empirical class prior\n",
       "      distribution.\n",
       "    * \"stratified\": the `predict_proba` method randomly samples one-hot\n",
       "      vectors from a multinomial distribution parametrized by the empirical\n",
       "      class prior probabilities.\n",
       "      The `predict` method returns the class label which got probability\n",
       "      one in the one-hot vector of `predict_proba`.\n",
       "      Each sampled row of both methods is therefore independent and\n",
       "      identically distributed.\n",
       "    * \"uniform\": generates predictions uniformly at random from the list\n",
       "      of unique classes observed in `y`, i.e. each class has equal\n",
       "      probability.\n",
       "    * \"constant\": always predicts a constant label that is provided by\n",
       "      the user. This is useful for metrics that evaluate a non-majority\n",
       "      class.\n",
       "\n",
       "      .. versionchanged:: 0.24\n",
       "         The default value of `strategy` has changed to \"prior\" in version\n",
       "         0.24.\n",
       "\n",
       "random_state : int, RandomState instance or None, default=None\n",
       "    Controls the randomness to generate the predictions when\n",
       "    ``strategy='stratified'`` or ``strategy='uniform'``.\n",
       "    Pass an int for reproducible output across multiple function calls.\n",
       "    See :term:`Glossary <random_state>`.\n",
       "\n",
       "constant : int or str or array-like of shape (n_outputs,), default=None\n",
       "    The explicit constant as predicted by the \"constant\" strategy. This\n",
       "    parameter is useful only for the \"constant\" strategy.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "classes_ : ndarray of shape (n_classes,) or list of such arrays\n",
       "    Unique class labels observed in `y`. For multi-output classification\n",
       "    problems, this attribute is a list of arrays as each output has an\n",
       "    independent set of possible classes.\n",
       "\n",
       "n_classes_ : int or list of int\n",
       "    Number of label for each output.\n",
       "\n",
       "class_prior_ : ndarray of shape (n_classes,) or list of such arrays\n",
       "    Frequency of each class observed in `y`. For multioutput classification\n",
       "    problems, this is computed independently for each output.\n",
       "\n",
       "n_features_in_ : int\n",
       "    Number of features seen during :term:`fit`.\n",
       "\n",
       "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
       "    Names of features seen during :term:`fit`. Defined only when `X` has\n",
       "    feature names that are all strings.\n",
       "\n",
       "n_outputs_ : int\n",
       "    Number of outputs.\n",
       "\n",
       "sparse_output_ : bool\n",
       "    True if the array returned from predict is to be in sparse CSC format.\n",
       "    Is automatically set to True if the input `y` is passed in sparse\n",
       "    format.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DummyRegressor : Regressor that makes predictions using simple rules.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> import numpy as np\n",
       ">>> from sklearn.dummy import DummyClassifier\n",
       ">>> X = np.array([-1, 1, 1, 1])\n",
       ">>> y = np.array([0, 1, 1, 1])\n",
       ">>> dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
       ">>> dummy_clf.fit(X, y)\n",
       "DummyClassifier(strategy='most_frequent')\n",
       ">>> dummy_clf.predict(X)\n",
       "array([1, 1, 1, 1])\n",
       ">>> dummy_clf.score(X, y)\n",
       "0.75\n",
       "\u001b[31mFile:\u001b[39m           /opt/anaconda3/envs/vmb_env_py311/lib/python3.11/site-packages/sklearn/dummy.py\n",
       "\u001b[31mType:\u001b[39m           type\n",
       "\u001b[31mSubclasses:\u001b[39m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DummyClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d1c31f-a7e2-4f24-b56e-c6c8a4f53e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (vmb_env_py311)",
   "language": "python",
   "name": "vmb_env_py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
